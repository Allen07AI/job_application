{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fafffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'You are a helpful assistant that evaluates '\n",
      "                          'candidate profiles and provides a rating score out '\n",
      "                          'of 100 based on their skills, experience, '\n",
      "                          'education, projects, and job role.',\n",
      "               'role': 'system'},\n",
      "              {'content': 'Skills: TensorFlow, NLP, Pytorch\\n'\n",
      "                          'Experience (Years): 10\\n'\n",
      "                          'Education: B.Sc\\n'\n",
      "                          'Projects Count: 8\\n'\n",
      "                          'Job Role: AI Researcher\\n'\n",
      "                          '\\n'\n",
      "                          'Rate this candidate out of 100 based on the '\n",
      "                          'information above.',\n",
      "               'role': 'user'},\n",
      "              {'content': '100', 'role': 'assistant'}]}\n",
      "Training file ID: file-UVoJDxAnLYTkdu3ZFvCDnY\n",
      "Validation file ID: file-VBhgvK4TrzirELsD2TrJAg\n",
      "Fine-tuning Job ID: ftjob-TtCR3d9iE5Mx6wFe15ya4IFn\n",
      "Status: validating_files\n",
      "Job ID: ftjob-TtCR3d9iE5Mx6wFe15ya4IFn\n",
      "Status: validating_files\n",
      "Trained Tokens: None\n",
      "Created fine-tuning job: ftjob-TtCR3d9iE5Mx6wFe15ya4IFn\n",
      "Validating training file: file-UVoJDxAnLYTkdu3ZFvCDnY and validation file: file-VBhgvK4TrzirELsD2TrJAg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Read your resume dataset\n",
    "resume_df = pd.read_csv(\"data/AI_Resume_Screening.csv\")\n",
    "# Modify the AI score\n",
    "resume_df['AI score (1-100)'] = resume_df['AI Score (0-100)'].apply(\n",
    "    lambda x: x - random.randint(1, 20) if x == 100 else x\n",
    ")\n",
    "\n",
    "# Define the system message\n",
    "system_message = \"You are a helpful assistant that evaluates candidate profiles and provides a rating score out of 100 based on their skills, experience, education, projects, and job role.\"\n",
    "\n",
    "# Function to create the user's message\n",
    "def create_user_message(row):\n",
    "    return (\n",
    "        f\"Skills: {row['Skills']}\\n\"\n",
    "        f\"Experience (Years): {row['Experience (Years)']}\\n\"\n",
    "        f\"Education: {row['Education']}\\n\"\n",
    "        f\"Projects Count: {row['Projects Count']}\\n\"\n",
    "        f\"Job Role: {row['Job Role']}\\n\\n\"\n",
    "        \"Rate this candidate out of 100 based on the information above.\"\n",
    "    )\n",
    "\n",
    "# Function to prepare each example conversation\n",
    "def prepare_example_conversation(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": create_user_message(row)},\n",
    "            {\"role\": \"assistant\", \"content\": str(row[\"AI Score (0-100)\"])},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Preview an example\n",
    "pprint(prepare_example_conversation(resume_df.iloc[0]))\n",
    "\n",
    "# Select a subset for training\n",
    "training_df = resume_df.loc[0:600]\n",
    "training_data = training_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "# Select a subset for validation\n",
    "validation_df = resume_df.loc[600:800]\n",
    "validation_data = validation_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "# Function to write jsonl files\n",
    "def write_jsonl(data_list: list, filename: str) -> None:\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)  \n",
    "    with open(filename, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)\n",
    "\n",
    "# Save training and validation datasets\n",
    "training_file_name = \"training/resume_finetune_training.jsonl\"\n",
    "write_jsonl(training_data, training_file_name)\n",
    "\n",
    "validation_file_name = \"training/resume_finetune_validation.jsonl\"\n",
    "write_jsonl(validation_data, validation_file_name)\n",
    "\n",
    "# Function to upload files\n",
    "def upload_file(file_name: str, purpose: str = \"fine-tune\") -> str:\n",
    "    with open(file_name, \"rb\") as file_fd:\n",
    "        response = client.files.create(file=file_fd, purpose=purpose)\n",
    "    return response.id\n",
    "\n",
    "# Upload your training and validation files\n",
    "training_file_id = upload_file(training_file_name)\n",
    "validation_file_id = upload_file(validation_file_name)\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)\n",
    "\n",
    "# Fine-tuning parameters\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Start fine-tuning job\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=MODEL,\n",
    "    suffix=\"resume-ai-score\",\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Fine-tuning Job ID:\", job_id)\n",
    "print(\"Status:\", response.status)\n",
    "\n",
    "# Function to check fine-tuning job status\n",
    "def check_job_status(job_id: str):\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(\"Job ID:\", response.id)\n",
    "    print(\"Status:\", response.status)\n",
    "    print(\"Trained Tokens:\", response.trained_tokens)\n",
    "\n",
    "# Check the job status\n",
    "check_job_status(job_id)\n",
    "\n",
    "# Function to monitor events (progress updates)\n",
    "def monitor_fine_tune(job_id: str):\n",
    "    response = client.fine_tuning.jobs.list_events(job_id)\n",
    "    events = response.data\n",
    "    events.reverse()\n",
    "    for event in events:\n",
    "        print(event.message)\n",
    "\n",
    "# Monitor progress\n",
    "monitor_fine_tune(job_id)"
   ]
  },
{
    "cell_type": "code",
    "execution_count": 2,
    "id": "6cb1e870",
    "metadata": {},
    "outputs": [
     {
      "ename": "RuntimeError",
      "evalue": "Fine-tuned model ID not found. Fine-tuning might still be in progress.",
      "output_type": "error",
      "traceback": [
       "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
       "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
       "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fine_tuned_model_id\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# After completion\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m fine_tuned_model_id \u001b[38;5;241m=\u001b[39m \u001b[43mget_fine_tuned_model_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuned Model ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, fine_tuned_model_id)\n",
       "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_fine_tuned_model_id\u001b[1;34m(job_id)\u001b[0m\n\u001b[0;32m      4\u001b[0m fine_tuned_model_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mfine_tuned_model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fine_tuned_model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuned model ID not found. Fine-tuning might still be in progress.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fine_tuned_model_id\n",
       "\u001b[1;31mRuntimeError\u001b[0m: Fine-tuned model ID not found. Fine-tuning might still be in progress."
      ]
     }
   ],
   "source": [
    "# Once the job is completed, retrieve fine-tuned model ID\n",
    "def get_fine_tuned_model_id(job_id: str) -> str:\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    fine_tuned_model_id = response.fine_tuned_model\n",
    "    if fine_tuned_model_id is None:\n",
    "        raise RuntimeError(\"Fine-tuned model ID not found. Fine-tuning might still be in progress.\")\n",
    "    return fine_tuned_model_id\n",
    "\n",
    "# After completion\n",
    "fine_tuned_model_id = get_fine_tuned_model_id(job_id)\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
    ],
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference\n",
    "\n",
    "# Select a sample from the dataset to test\n",
    "test_df = resume_df.loc[800:1000]  \n",
    "test_row = test_df.iloc[0]       \n",
    "\n",
    "# Prepare the input messages\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "test_messages.append({\"role\": \"user\", \"content\": create_user_message(test_row)})\n",
    "\n",
    "# Display the test input\n",
    "pprint(test_messages)\n",
    "\n",
    "# Call the fine-tuned model for prediction\n",
    "response = client.chat.completions.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages=test_messages,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Output the model's prediction\n",
    "print(\"Predicted AI Score:\", response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
